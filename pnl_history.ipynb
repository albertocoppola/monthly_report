{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "1be2c7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "ccda04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = pd.read_csv(\"portfolio_positions_exploded.csv\")\n",
    "costs = pd.read_csv(\"portfolio_costs_exploded.csv\")\n",
    "\n",
    "# filtra os custos por quem nao tem pnl nem exposiçao\n",
    "costs = costs[~(costs['dtd_custos_fin'] == 0) | ~(costs['financial_value'] == 0)]\n",
    "\n",
    "# filtra posicao pra quem nao tem pnl\n",
    "positions = positions[~(positions['dtd_ativo_fin'] == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae188382",
   "metadata": {},
   "source": [
    "Construção do PNL de Posições"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a647468",
   "metadata": {},
   "source": [
    "DTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "c8f5bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions['overview_date'] = pd.to_datetime(positions['overview_date'])\n",
    "costs['overview_date'] = pd.to_datetime(costs['overview_date'])\n",
    "positions = positions.sort_values(['portfolio_id','instrument_id','portfolio_origem','overview_date'])\n",
    "\n",
    "# Pego exposição e nav do dia anterior pra calcular o pnl diário\n",
    "positions['exposure_value_ontem'] = (\n",
    "    positions.groupby(['portfolio_id','instrument_id','portfolio_origem'])['exposure_value']\n",
    "    .shift(1)\n",
    ")\n",
    "\n",
    "# DataFrame com NAV diário único por portfólio\n",
    "navs = (\n",
    "    positions\n",
    "    .groupby(['portfolio_id', 'overview_date'])['portfolio_nav']\n",
    "    .first()  # ou .max(), se sempre igual\n",
    "    .reset_index()\n",
    "    .sort_values(['portfolio_id', 'overview_date'])\n",
    ")\n",
    "\n",
    "# NAV de ontem\n",
    "navs['portfolio_nav_ontem'] = navs.groupby('portfolio_id')['portfolio_nav'].shift(1)\n",
    "\n",
    "# Merge no df de posições, para cada linha pegar o NAV de ontem certo para o portfolio_id e overview_date\n",
    "positions = positions.merge(\n",
    "    navs[['portfolio_id', 'overview_date', 'portfolio_nav_ontem']],\n",
    "    on=['portfolio_id', 'overview_date'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Tambem faço o merge do nav_ontem em costs pra utilizar deopis\n",
    "costs = costs.merge(\n",
    "    navs[['portfolio_id', 'overview_date', 'portfolio_nav_ontem']],\n",
    "    left_on=['root_portfolio', 'overview_date'],\n",
    "    right_on=['portfolio_id', 'overview_date'],\n",
    "    how='left'\n",
    ").drop(columns=['portfolio_id'])\n",
    "\n",
    "# Calculo do pnl diário do ativo e da carteira\n",
    "positions['dtd_ativo_pct'] = positions['dtd_ativo_fin'] / positions['exposure_value_ontem']\n",
    "positions['dtd_carteira_pct'] = positions['dtd_ativo_fin'] / positions['portfolio_nav_ontem']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49056f66",
   "metadata": {},
   "source": [
    "MTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "47286d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions['Year'] = positions['overview_date'].dt.year\n",
    "positions['Month'] = positions['overview_date'].dt.month\n",
    "\n",
    "# Calcula ano/mês do mês anterior\n",
    "positions['Month_after'] = positions['Month'] + 1\n",
    "positions['Year_after'] = positions['Year']\n",
    "positions.loc[positions['Month_after'] == 13, 'Month_after'] = 1\n",
    "positions.loc[positions['Month'] == 12, 'Year_after'] += 1\n",
    "\n",
    "# Tabela com último exposure_value do mês para cada grupo\n",
    "last_exposure_month = (\n",
    "    positions\n",
    "    .groupby(['portfolio_id','instrument_id','portfolio_origem','Year','Month'])\n",
    "    .apply(lambda g: g.loc[g['overview_date'] == g['overview_date'].max()])\n",
    "    .reset_index(drop=True)\n",
    ")[['portfolio_id','instrument_id','portfolio_origem','Year_after','Month_after','exposure_value']]\n",
    "\n",
    "last_exposure_month = last_exposure_month.rename(\n",
    "    columns={'Year_after':'Year','Month_after':'Month','exposure_value':'exposure_value_prev'}\n",
    ")\n",
    "\n",
    "# Faz merge para trazer o exposure_value do mes anterior para cada linha\n",
    "positions = positions.merge(\n",
    "    last_exposure_month,\n",
    "    on=['portfolio_id','instrument_id','portfolio_origem','Year','Month'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Tabela com último portfolio_nav do mês para cada grupo (faço o groupby de novo pra não incluir o instrument_id aqui)\n",
    "last_nav_month = (\n",
    "    positions\n",
    "    .groupby(['portfolio_id','portfolio_origem','Year','Month'])\n",
    "    .apply(lambda g: g.loc[g['overview_date'] == g['overview_date'].max()])\n",
    "    .reset_index(drop=True)\n",
    ")[['portfolio_id','portfolio_origem','Year_after','Month_after','portfolio_nav']]\n",
    "\n",
    "last_nav_month = last_nav_month.rename(\n",
    "    columns={'Year_after':'Year','Month_after':'Month', 'portfolio_nav':'portfolio_nav_prev'}\n",
    ")\n",
    "\n",
    "last_nav_month = last_nav_month.drop_duplicates()\n",
    "\n",
    "# Faz merge para trazer o nav do mes anterior para cada linha\n",
    "positions = positions.merge(\n",
    "    last_nav_month,\n",
    "    on=['portfolio_id','portfolio_origem','Year','Month'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "positions = positions.sort_values(['portfolio_id','instrument_id','portfolio_origem','overview_date'])\n",
    "\n",
    "\n",
    "# Calcula o PnL MTD financeiro pra todos os dias:\n",
    "positions['mtd_ativo_fin'] = positions.groupby(\n",
    "    ['portfolio_id', 'instrument_id', 'portfolio_origem', 'Year', 'Month']\n",
    ")['dtd_ativo_fin'].cumsum()\n",
    "\n",
    "positions['mtd_ativo_pct'] = positions['mtd_ativo_fin'] / positions['exposure_value_prev']\n",
    "\n",
    "positions['mtd_carteira_pct'] = positions['mtd_ativo_fin'] / positions['portfolio_nav_prev']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88da03f",
   "metadata": {},
   "source": [
    "Expansão do PNL MTD para ativos que foram zerados ao longo do mês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PnL MTD\n",
    "group_cols = ['portfolio_id','instrument_id','portfolio_origem','Year','Month']\n",
    "all_dates = positions.groupby(group_cols)['overview_date'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "# Gera linhas para todos os dias do mês para cada ativo\n",
    "expanded = []\n",
    "for _, row in all_dates.iterrows():\n",
    "    year = row['Year']\n",
    "    month = row['Month']\n",
    "    filtro = (positions['overview_date'].dt.year == year) & (positions['overview_date'].dt.month == month)\n",
    "\n",
    "    # pega o último dia do mês de forma automática\n",
    "    dates = list(positions['overview_date'][filtro].drop_duplicates())\n",
    "    for date in dates:\n",
    "        expanded.append({**row, 'overview_date': date})\n",
    "\n",
    "calendar = pd.DataFrame(expanded)\n",
    "\n",
    "# Merge calendar com positions\n",
    "positions_full = pd.merge(calendar, positions, on=group_cols + ['overview_date'], how='left')\n",
    "\n",
    "# Forward fill do PnL e das outras colunas por ativo/mês\n",
    "positions_full = positions_full.sort_values(group_cols + ['overview_date'])\n",
    "\n",
    "# positions_full['mtd_carteira_pct'] = positions_full.groupby(group_cols)['mtd_carteira_pct'].ffill()\n",
    "\n",
    "categoria_cols = [col for col in positions_full.columns if col.startswith('grupo_')]\n",
    "categoria_cols = ['mtd_ativo_fin','mtd_ativo_pct', 'mtd_carteira_pct'] + categoria_cols\n",
    "positions_full[categoria_cols] = (\n",
    "    positions_full.groupby(['portfolio_id', 'instrument_id', 'portfolio_origem','Year','Month'])[categoria_cols]\n",
    "    .ffill()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316010ed",
   "metadata": {},
   "source": [
    "YTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "3aa2c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positions_full['Year_after'] = positions_full['Year'] + 1\n",
    "\n",
    "# # Tabela com último exposure_value do ano para cada grupo\n",
    "# last_exposure_year = (\n",
    "#     positions_full\n",
    "#     .groupby(['portfolio_id','instrument_id','portfolio_origem','Year'])\n",
    "#     .apply(lambda g: g.loc[g['overview_date'] == g['overview_date'].max()])\n",
    "#     .reset_index(drop=True)\n",
    "# )[['portfolio_id','instrument_id','portfolio_origem','Year_after','exposure_value']]\n",
    "\n",
    "# last_exposure_year = last_exposure_year.rename(\n",
    "#     columns={'Year_after':'Year','exposure_value':'exposure_value_ytd_prev'}\n",
    "# )\n",
    "\n",
    "# # Faz merge para trazer o exposure_value do mes anterior para cada linha\n",
    "# positions_full = positions_full.merge(\n",
    "#     last_exposure_year,\n",
    "#     on=['portfolio_id','instrument_id','portfolio_origem','Year'],\n",
    "#     how='left'\n",
    "# )\n",
    "\n",
    "# # Tabela com último portfolio_nav do mês para cada grupo (faço o groupby de novo pra não incluir o instrument_id aqui)\n",
    "# last_nav_year = (\n",
    "#     positions_full\n",
    "#     .groupby(['portfolio_id','portfolio_origem','Year'])\n",
    "#     .apply(lambda g: g.loc[g['overview_date'] == g['overview_date'].max()])\n",
    "#     .reset_index(drop=True)\n",
    "# )[['portfolio_id','portfolio_origem','Year_after','portfolio_nav']]\n",
    "\n",
    "# last_nav_year = last_nav_year.rename(\n",
    "#     columns={'Year_after':'Year','portfolio_nav':'portfolio_nav_ytd_prev'}\n",
    "# )\n",
    "\n",
    "# last_nav_year = last_nav_year.drop_duplicates()\n",
    "# last_nav_year = last_nav_year.dropna()\n",
    "\n",
    "# # Faz merge para trazer o nav do mes anterior para cada linha\n",
    "# positions_full = positions_full.merge(\n",
    "#     last_nav_year,\n",
    "#     on=['portfolio_id','portfolio_origem','Year'],\n",
    "#     how='left'\n",
    "# )\n",
    "\n",
    "# positions_full = positions_full.sort_values(['portfolio_id','instrument_id','portfolio_origem','overview_date'])\n",
    "\n",
    "# Calcula o PnL ytd financeiro pra todos os dias:\n",
    "positions_full['ytd_ativo_fin'] = positions_full.groupby(\n",
    "    ['portfolio_id', 'instrument_id', 'portfolio_origem', 'Year']\n",
    ")['dtd_ativo_fin'].cumsum()\n",
    "\n",
    "# positions_full['ytd_ativo_pct'] = positions_full['ytd_ativo_fin'] / positions_full['exposure_value_ytd_prev']\n",
    "\n",
    "# positions_full['ytd_carteira_pct'] = positions_full['ytd_ativo_fin'] / positions_full['portfolio_nav_ytd_prev']\n",
    "\n",
    "positions_full.drop(columns=(['min','max']),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a944ee",
   "metadata": {},
   "source": [
    "Tratamento do DF para exportação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "52d78409",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_full_filtrado = positions_full[[\n",
    "    'portfolio_id','portfolio_origem','book_name','overview_date','instrument_id',\n",
    "    'dtd_ativo_fin','dtd_ativo_pct','dtd_carteira_pct','ytd_ativo_fin'] + categoria_cols]\n",
    "positions_full_filtrado.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094be0b8",
   "metadata": {},
   "source": [
    "Construção do PNL de Custos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "6cd6d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs['overview_date'] = pd.to_datetime(costs['overview_date'])\n",
    "\n",
    "costs['Year'] = costs['overview_date'].dt.year\n",
    "costs['Month'] = costs['overview_date'].dt.month\n",
    "\n",
    "costs = costs.sort_values(['origin_portfolio_id', 'root_portfolio', 'overview_date'])\n",
    "\n",
    "# Calcula ano/mês do mês anterior\n",
    "costs['Month_after'] = costs['Month'] + 1\n",
    "costs['Year_after'] = costs['Year']\n",
    "costs.loc[costs['Month_after'] == 13, 'Month_after'] = 1\n",
    "costs.loc[costs['Month'] == 12, 'Year_after'] += 1\n",
    "\n",
    "# Faz merge para trazer o nav do mes anterior para cada linha\n",
    "costs = costs.merge(\n",
    "    last_nav_month,\n",
    "    left_on=['root_portfolio','origin_portfolio_id','Year','Month'],\n",
    "    right_on=['portfolio_id','portfolio_origem','Year','Month'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "costs = costs.sort_values(['category_name','origin_portfolio_id','root_portfolio','overview_date'])\n",
    "\n",
    "\n",
    "# Calcula o PnL MTD pra qualquer dia:\n",
    "costs['mtd_custos_fin'] = costs.groupby(\n",
    "    ['category_name','origin_portfolio_id','root_portfolio','Year','Month']\n",
    ")['dtd_custos_fin'].cumsum()\n",
    "\n",
    "costs['ytd_custos_fin'] = costs.groupby(\n",
    "    ['category_name','origin_portfolio_id','root_portfolio','Year']\n",
    ")['dtd_custos_fin'].cumsum()\n",
    "\n",
    "costs['dtd_custos_pct'] = costs['dtd_custos_fin'] / costs['portfolio_nav_ontem']\n",
    "costs['mtd_custos_pct'] = costs['mtd_custos_fin'] / costs['portfolio_nav_prev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "589608ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PnL MTD\n",
    "group_cols = ['category_name','origin_portfolio_id','root_portfolio','Year','Month']\n",
    "all_dates = costs.groupby(group_cols)['overview_date'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "# Gera linhas para todos os dias do mês para cada ativo\n",
    "expanded = []\n",
    "for _, row in all_dates.iterrows():\n",
    "    year = row['Year']\n",
    "    month = row['Month']\n",
    "    filtro = (costs['overview_date'].dt.year == year) & (costs['overview_date'].dt.month == month)\n",
    "\n",
    "    # pega o último dia do mês de forma automática\n",
    "    dates = list(costs['overview_date'][filtro].drop_duplicates())\n",
    "    for date in dates:\n",
    "        expanded.append({**row, 'overview_date': date})\n",
    "\n",
    "calendar = pd.DataFrame(expanded)\n",
    "\n",
    "# Passo 2: Merge calendar com costs\n",
    "costs_full = pd.merge(calendar, costs, on=group_cols + ['overview_date'], how='left')\n",
    "\n",
    "# Passo 3: Forward fill do PnL e das outras colunas por ativo/mês\n",
    "costs_full = costs_full.sort_values(group_cols + ['overview_date'])\n",
    "costs_full['mtd_custos_pct'] = costs_full.groupby(group_cols)['mtd_custos_pct'].ffill()\n",
    "\n",
    "costs_full['book_name'] = \"Caixas e Provisionamentos\"\n",
    "\n",
    "# Tratamento do DF para exportação\n",
    "costs_full_filtrado = costs_full[[\n",
    "    'overview_date','category_name','book_name','origin_portfolio_id','root_portfolio',\n",
    "    'dtd_custos_fin', 'portfolio_id',\n",
    "    'mtd_custos_fin','dtd_custos_pct','mtd_custos_pct','ytd_custos_fin']]\n",
    "\n",
    "costs_full_filtrado.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476c89bb",
   "metadata": {},
   "source": [
    "Concatena a tabela no csv de posições e custos, reprocessando as datas coincidentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "ac7915ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    main_csv_position = pd.read_csv(\"positions_pnl_history.csv\",parse_dates=['overview_date'])\n",
    "    main_csv_costs = pd.read_csv(\"costs_pnl_history.csv\",parse_dates=['overview_date'])\n",
    "\n",
    "    main_csv_position.to_csv(\"positions_pnl_history_backup.csv\", index=False)\n",
    "    main_csv_costs.to_csv(\"costs_pnl_history_backup.csv\", index=False)\n",
    "\n",
    "    \"\"\" Para posições: \"\"\"\n",
    "    # Primeiro: remove do main_csv_position todas as linhas que têm datas que existem no positions_full_filtrado\n",
    "    main_csv_filtrado = main_csv_position[~main_csv_position['overview_date'].isin(positions_full_filtrado['overview_date'])]\n",
    "\n",
    "    # Segundo: concatena os dois\n",
    "    df_resultado = pd.concat([main_csv_filtrado, positions_full_filtrado], ignore_index=True)\n",
    "\n",
    "    # Terceiro: opcional - reordenar por data, se quiser\n",
    "    df_resultado = df_resultado.sort_values('overview_date').reset_index(drop=True)\n",
    "\n",
    "    #Exporta CSV\n",
    "    df_resultado.to_csv(\"positions_pnl_history.csv\", index=False)\n",
    "\n",
    "\n",
    "    \"\"\" Para custos: \"\"\"\n",
    "    # Primeiro: remove do main_csv_costs todas as linhas que têm datas que existem no costs_full_filtrado\n",
    "    main_csv_filtrado = main_csv_costs[~main_csv_costs['overview_date'].isin(costs_full_filtrado['overview_date'])]\n",
    "\n",
    "    # Segundo: concatena os dois\n",
    "    df_resultado = pd.concat([main_csv_filtrado, costs_full_filtrado], ignore_index=True)\n",
    "\n",
    "    # Terceiro: opcional - reordenar por data, se quiser\n",
    "    df_resultado = df_resultado.sort_values('overview_date').reset_index(drop=True)\n",
    "\n",
    "    #Exporta CSV\n",
    "    df_resultado.to_csv(\"costs_pnl_history.csv\", index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Not processed.\")\n",
    "    #Exporta CSV\n",
    "    # positions_full_filtrado.to_csv(\"positions_pnl_history.csv\", index=False)\n",
    "    # costs_full_filtrado.to_csv(\"costs_pnl_history.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d044d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
